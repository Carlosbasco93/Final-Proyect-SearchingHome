{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27f8233a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14d80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "# Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests_html import HTMLSession\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Otros\n",
    "import random\n",
    "from datetime import date\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef08da",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663f90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"à\", \"a\"),\n",
    "        (\"è\", \"e\"),\n",
    "        (\"ì\", \"i\"),\n",
    "        (\"ò\", \"o\"),\n",
    "        (\"ù\", \"u\"),\n",
    "    )\n",
    "    for a, b in replacements:\n",
    "        s = s.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def check_proxys():\n",
    "    proxylist = []\n",
    "    valid_proxys = []\n",
    "\n",
    "    with open('data/proxylist.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            proxylist.append(row[0])\n",
    "\n",
    "    def extract(proxy):\n",
    "        try:\n",
    "            r = requests.get('https://httpbin.org/ip', proxies={'http': proxy, 'https': proxy}, timeout=3)\n",
    "            #print(r.json(),' - working')\n",
    "            valid_proxys.append(proxy)\n",
    "        except:\n",
    "            #print(f'{proxy} - failed')\n",
    "            pass\n",
    "        return proxy\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as exector:\n",
    "        exector.map(extract, proxylist)\n",
    "        \n",
    "    return valid_proxys'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef22d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_agents_list():\n",
    "    \n",
    "    user_agents = []\n",
    "    \n",
    "    with open('data/user_agents.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            user_agents.append(row[0])\n",
    "\n",
    "    return user_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_zonas():\n",
    "    \n",
    "    user_agents = user_agents_list()\n",
    "    user = user_agents[random.randrange(0,len(user_agents))]\n",
    "    \n",
    "    r = session.request(method='GET',url=\"https://www.pisos.com/pisos/\",headers={'user-agent':user})#,proxies={'http': proxy, 'https': proxy})\n",
    "    \n",
    "    return [e.split('-')[1][:-1] for e in r.html.links if '/venta/'in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcab3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_carac(termino,lista_carac):    \n",
    "    \n",
    "    res = ''\n",
    "    \n",
    "    i=0\n",
    "    encontrado = False\n",
    "    while i < len(lista_carac) and encontrado == False:\n",
    "        if termino in lista_carac[i]:\n",
    "            encontrado = True\n",
    "            if len(lista_carac[i].split(':'))>1:\n",
    "                res = lista_carac[i].split(':')[1].strip()\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddd6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestión de 1 sóla vivienda\n",
    "def one_house(url):\n",
    "    \n",
    "    user = user_agents[random.randrange(0,len(user_agents))]\n",
    "    \n",
    "    try:\n",
    "        r = session.request(method='GET',url=url, headers={'user-agent':user},timeout=(10))#,proxies={'http': proxy, 'https': proxy})\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "\n",
    "        if soup.find('p', class_=\"notification__disabled--title\") == None and soup.find('div', class_=\"no-results\")== None:\n",
    "            \n",
    "            if soup.find_all('li',class_='charblock-element more-padding') != None:\n",
    "                lista_carac = soup.find_all('li',class_='charblock-element more-padding')\n",
    "                lista_carac = [e.text.replace('\\n','').strip() for e in lista_carac]\n",
    "            else:\n",
    "                lista_carac = []\n",
    "                \n",
    "            if soup.find_all('li',class_='charblock-element element-with-bullet certificate-clasification') != None:\n",
    "                certificado = soup.find_all('li',class_='charblock-element element-with-bullet certificate-clasification')\n",
    "                certificado = [e.text.replace('\\n','').strip() for e in certificado]\n",
    "            else:\n",
    "                certificado = []\n",
    "                \n",
    "            if soup.find('h1') != None:\n",
    "                titulo = soup.find('h1').text\n",
    "            else:\n",
    "                titulo = ''\n",
    "                \n",
    "            if soup.find('h2') != None:\n",
    "                zona = soup.find('h2').text\n",
    "            else:\n",
    "                zona = ''\n",
    "                \n",
    "            if soup.find('span',class_='h1 jsPrecioH1') != None:\n",
    "                precio = soup.find('span',class_='h1 jsPrecioH1').text[:-2].replace('.','')\n",
    "            else:\n",
    "                precio = ''\n",
    "                \n",
    "            if soup.find(id='descriptionBody') != None:\n",
    "                descr = soup.find(id='descriptionBody').text.split('\\n')[1].strip()\n",
    "            else:\n",
    "                descr = ''\n",
    "            \n",
    "            if soup.find('div', class_=\"updated-date\") != None:\n",
    "                f_entrada = soup.find('div', class_=\"updated-date\").text.strip().split(' ')[2]\n",
    "            else:\n",
    "                f_entrada = f\"{date.today().day}/{date.today().month}/{date.today().year}\"\n",
    "                \n",
    "            vivienda = {\n",
    "                'id':url[-19:-1],\n",
    "                'titulo':titulo, \n",
    "                'zona':zona, \n",
    "                'precio':precio, \n",
    "                'descripcion': descr,\n",
    "                'superficie_construida_m': busqueda_carac('Superficie construida',lista_carac).replace('.','')[:-3],\n",
    "                'superficie_util_m': busqueda_carac('útil',lista_carac).replace('.','')[:-3],\n",
    "                'superficie_solar_m': busqueda_carac('solar',lista_carac).replace('.','')[:-3],\n",
    "                'habitaciones': busqueda_carac('Habitaciones',lista_carac),\n",
    "                'banyos': busqueda_carac('Baños',lista_carac),\n",
    "                'planta': busqueda_carac('Planta',lista_carac)[:-1],\n",
    "                'antiguedad': busqueda_carac('Antigüedad',lista_carac),\n",
    "                'gastos_comunidad': busqueda_carac('comunidad',lista_carac),\n",
    "                'conservacion': busqueda_carac('Conservación',lista_carac),\n",
    "                'f_entrada': f_entrada,\n",
    "                'url':url\n",
    "            }\n",
    "\n",
    "            #\n",
    "            # IMPORTANTE . Queda pendiente incluir el eur_m en el dataframe\n",
    "            #\n",
    "            #if vivienda['superficie_construida_m'] != '':\n",
    "            #    vivienda['eur_m']= int(vivienda['precio'])/ int(vivienda['superficie_construida_m'])\n",
    "            #else:\n",
    "            #    vivienda['eur_m']= ''\n",
    "\n",
    "            time.sleep(random.randint(0,2))\n",
    "\n",
    "            return vivienda\n",
    "        else:\n",
    "            #print('Anuncio caido', url)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86068c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_alive(link):\n",
    "    user = user_agents[random.randrange(0,len(user_agents))]\n",
    "    \n",
    "    try:\n",
    "        r = session.request(method='GET',url=link, headers={'user-agent':user},timeout=(10))#,proxies={'http': proxy, 'https': proxy})\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "\n",
    "        if soup.find('p', class_=\"notification__disabled--title\") != None or soup.find('div', class_=\"no-results\")!= None:\n",
    "            return link\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1773258",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05baef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar componentes\n",
    "session = HTMLSession()\n",
    "\n",
    "#valid_proxys = check_proxys()\n",
    "user_agents = user_agents_list()\n",
    "zonas = lista_zonas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Obtener TODOS los enlaces de la web por zonas\n",
    "\n",
    "user = user_agents[random.randrange(0,len(user_agents))]\n",
    "#proxy = valid_proxys[random.randrange(0,len(valid_proxys))]\n",
    "links_por_zonas = {}\n",
    "\n",
    "for zona in zonas:\n",
    "    \n",
    "    # Primera página\n",
    "    i = 1\n",
    "    continuar = True\n",
    "    r = session.request(method='GET',url=f\"https://www.pisos.com/venta/pisos-{zona}/fecharecientedesde-desc/\",headers={'user-agent':user})#,proxies={'http': proxy, 'https': proxy})\n",
    "    links = [e for e in r.html.absolute_links if '/comprar/'in e]\n",
    "    check_duplicates = links\n",
    "    \n",
    "    # Resto de páginas \n",
    "    while r.status_code == 200 and i < 101 and continuar == True: \n",
    "        time.sleep(random.randint(0,2)) # Modificado de 5 a 2 para paralelizar\n",
    "        i+=1\n",
    "        user = user_agents[random.randrange(0,len(user_agents))]\n",
    "        #proxy = valid_proxys[random.randrange(0,len(valid_proxys))]\n",
    "\n",
    "        try:\n",
    "            r = session.request(method='GET',url=f\"https://www.pisos.com/venta/pisos-{zona}/fecharecientedesde-desc/{i}/\", headers={'user-agent':user})#,proxies={'http': proxy, 'https': proxy})\n",
    "\n",
    "        except:\n",
    "            print('Nos han pillado. Hemos llegado a la página',i, 'Zona:', zona)\n",
    "\n",
    "        else:\n",
    "            if r.status_code == 200:\n",
    "                \n",
    "                links_aux = [e for e in r.html.absolute_links if '/comprar/'in e]\n",
    "                \n",
    "                if check_duplicates != links_aux:\n",
    "                    \n",
    "                    check_duplicates = links_aux\n",
    "                    for link in links_aux:\n",
    "                        links.append(link)\n",
    "                else:\n",
    "                    continuar = False\n",
    "                    \n",
    "    links_por_zonas[zona] = links\n",
    "\n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c06af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra links obtenidos y elimina duplicados por comunidad\n",
    "\n",
    "for key in links_por_zonas:\n",
    "    print('Zona', key)\n",
    "    print('Enlaces obtenidos:',len(links_por_zonas[key]))\n",
    "    links_por_zonas[key] = list(set(links_por_zonas[key]))\n",
    "    print('Enlaces únicos:',len(links_por_zonas[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce311ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de enlaces\n",
    "\n",
    "with open('data/links.csv','w') as file:\n",
    "    for key in links_por_zonas:\n",
    "        file.write(key)\n",
    "        file.write('\\n')\n",
    "        for link in links_por_zonas[key]:\n",
    "            file.write(link)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248bc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de enlaces del csv\n",
    "\n",
    "links_por_zonas=[]\n",
    "\n",
    "with open('data/links.csv', 'r') as fichero:\n",
    "    for linea in fichero.readlines():\n",
    "        if 'http' in linea:\n",
    "            links_por_zonas.append(linea.strip())\n",
    "len(links_por_zonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos enlaces comunes entre comunidades\n",
    "\n",
    "links_por_zonas = list(set(links_por_zonas))\n",
    "len(links_por_zonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta a la BBDD para saber si los enlaces ya están guardados\n",
    "\n",
    "con = sqlite3.connect('pisos.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT url FROM pisos''')\n",
    "links_bbdd = cur.fetchall()\n",
    "links_bbdd = [e[0] for e in links_bbdd]\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "links_por_zonas = [e for e in links_por_zonas if e not in links_bbdd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links_por_zonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b355f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ejecutar aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a58c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for link in links_por_zonas:\n",
    "        futures.append(executor.submit(one_house, link))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        #print(future.result())\n",
    "        data.append(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37666719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlaces fallidos\n",
    "\n",
    "i = 0\n",
    "for e in data:\n",
    "    if e == None:\n",
    "        i+=1\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a333e",
   "metadata": {},
   "source": [
    "## Limpiar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55673f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_nulos = [e for e in data if e != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9738c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe71449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de dataframe\n",
    "df = pd.DataFrame(data_no_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3337ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027ecf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de formato a columnas a numero\n",
    "num_cols = df.columns.drop(['id', 'zona','titulo', 'descripcion', 'habitaciones', 'banyos', 'planta', 'antiguedad', 'gastos_comunidad', 'conservacion', 'url', 'f_entrada'])\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce') \n",
    "\n",
    "\n",
    "# Reemplazo por nulos valores vacios\n",
    "df.habitaciones = df.habitaciones.replace('', np.nan) \n",
    "df.banyos = df.banyos.replace('', np.nan)\n",
    "df.antiguedad = df.antiguedad.replace('', None)\n",
    "df.gastos_comunidad = df.gastos_comunidad.replace('', None)\n",
    "df.conservacion = df.conservacion.replace('', None)\n",
    "\n",
    "\n",
    "# Nuevas columna eur_m\n",
    "df['eur_m'] = df.precio/df.superficie_construida_m\n",
    "\n",
    "\n",
    "#Limpieza de valores no deseados\n",
    "df = df[~df.eur_m.isna()].reset_index(drop=True) #Eliminación de viviendas sin precio o sin metros cuadrados\n",
    "df = df[(df.superficie_construida_m>20)&(df.superficie_construida_m<800)].reset_index(drop=True) #Eliminación de viviendas que tengan menos de 20 metros construidos y mas de 800\n",
    "\n",
    "#Eliminación de fincas y estudios\n",
    "bad_indexs = []\n",
    "for ind, e in enumerate(df.descripcion): \n",
    "    if 'estudio' in e:\n",
    "        bad_indexs.append(ind)\n",
    "for ind, e in enumerate(df.descripcion[(df.superficie_solar_m==df.superficie_construida_m)&(df.habitaciones.isna())]): \n",
    "    if 'finca' in e:\n",
    "        bad_indexs.append(ind)\n",
    "\n",
    "df = df.drop(bad_indexs).reset_index(drop=True) \n",
    "\n",
    "\n",
    "# Nueva columna municipio\n",
    "df['municipio'] = [e.split('(')[1].split(')')[0] if '(' in e else e for e in df.zona]\n",
    "\n",
    "#Normalización de formatos y gestion de nulos\n",
    "df.zona = [e.split('(')[0] for e in df.zona]\n",
    "df.municipio = [e.split('.')[1].strip() if '.' in e else e for e in df.municipio]\n",
    "df.municipio = [e.replace('Capital','').strip() for e in df.municipio]\n",
    "df.municipio = df.municipio.apply(normalize)\n",
    "\n",
    "#Incluimos CPs de municipios\n",
    "df.municipio = [e.upper() for e in df.municipio]\n",
    "codigos_p = pd.read_csv('data/cp_data.csv',sep=';')\n",
    "codigos_p.zona = [e.split('(')[0].strip() for e in codigos_p.zona]\n",
    "dict_com_cp = dict(zip(codigos_p.zona, codigos_p.cp))\n",
    "df['codigo_postal'] = df.municipio.map(dict_com_cp)\n",
    "\n",
    "#Asignamos comunidades con CPs de municipios\n",
    "df['comunidad'] = [str(e)[2:4] for e in df.codigo_postal]\n",
    "leyenda_cp = pd.read_csv('data/leyenda_cp.csv',sep=';')\n",
    "dict_leyenda = dict(zip([e[:2] for e in leyenda_cp.cod], leyenda_cp.comunidad)) #Habria que alimentar el csv para los null\n",
    "df.comunidad = df.comunidad.map(dict_leyenda)\n",
    "\n",
    "# Por el momento reventamos los 3000 nulos de comunidad\n",
    "bad_indexs = df[df.comunidad.isna()].index.values\n",
    "df = df.drop(bad_indexs).reset_index(drop=True) \n",
    "\n",
    "df.comunidad = df.comunidad.apply(normalize) #Ahora puedo normalizar\n",
    "df['active']=1\n",
    "df['tmstmp']=f\"{date.today().day}/{date.today().month}/{date.today().year}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54db87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenación de columnas\n",
    "df = df[['id', 'titulo', 'zona','municipio', 'comunidad', 'codigo_postal','precio', 'eur_m', 'descripcion',\n",
    "       'superficie_construida_m', 'superficie_util_m', 'superficie_solar_m',\n",
    "       'habitaciones', 'banyos', 'planta', 'antiguedad', 'gastos_comunidad',\n",
    "       'conservacion', 'url', 'f_entrada','active', 'tmstmp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d60ff",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bac113bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de la conexión con la BBDD\n",
    "\n",
    "con = sqlite3.connect('pisos.db', check_same_thread=False)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicialización de la tabla\n",
    "\n",
    "df = df.T\n",
    "list_to_db = [df[i] for i in range (0, df.shape[1])]\n",
    "\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS pisos\n",
    "                    (id text PRIMARY KEY, \n",
    "                    titulo text,\n",
    "                    zona text,\n",
    "                    municipio text,\n",
    "                    comunidad text,\n",
    "                    codigo_postal text,\n",
    "                    precio real, \n",
    "                    eur_m real,\n",
    "                    descripcion text, \n",
    "                    superficie_construida_m real, \n",
    "                    superficie_util_m real,\n",
    "                    superficie_solar_m real,\n",
    "                    habitaciones int,\n",
    "                    banyos int,\n",
    "                    planta text,\n",
    "                    antiguedad text,\n",
    "                    gastos_comunidad text,\n",
    "                    conservacion text,\n",
    "                    url text,\n",
    "                    f_entrada text,\n",
    "                    active bool,\n",
    "                    tmstmp text\n",
    "                    )\n",
    "            ''')\n",
    "\n",
    "\n",
    "# Inserción de valores\n",
    "\n",
    "cur.executemany(\"INSERT OR IGNORE INTO pisos VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\",list_to_db)\n",
    "con.commit()\n",
    "\n",
    "df = df.T #Restablecemos el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Actualizamos los valores de alive y tmstmp\n",
    "\n",
    "cur.execute('''SELECT url FROM pisos WHERE active = 1''')\n",
    "links_bbdd = cur.fetchall()\n",
    "links_bbdd = [e[0] for e in links_bbdd]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for link in links_bbdd:\n",
    "        aux = executor.submit(check_alive, link)\n",
    "        if aux != None:\n",
    "            futures.append(aux)\n",
    "\n",
    "for link_ko in futures:\n",
    "    cur.execute(f'''SELECT id FROM pisos WHERE url = \"{link}\"''')\n",
    "    id_bbdd = cur.fetchone()            \n",
    "    cur.execute('''UPDATE pisos SET active = (?) WHERE id = (?)''', ('0', id_bbdd[0]) )\n",
    "    cur.execute('''UPDATE pisos SET tmstmp = (?) WHERE id = (?)''', (f'{date.today().day}/{date.today().month}/{date.today().year}', id_bbdd[0]) )\n",
    "    \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJECUTAR SIEMPRE ANTES DE CERRAR\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af701290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para actualizar cualquier columna (tmstmp ahora)\n",
    "\n",
    "#for i in range(len(df.id)):\n",
    "#    cur.execute('''UPDATE pisos SET tmstmp = (?) WHERE id = (?)''', (df.tmstmp[i], df.id[i]) )\n",
    "#con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca666f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.execute('''SELECT id FROM pisos WHERE url = \"https://www.pisos.com/comprar/duplex-huelves_centro_urbano-945856909855543_109800/\"''')\n",
    "#cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d107ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plantilla para eliminar registros\n",
    "\n",
    "#con = sqlite3.connect('pisos.db')\n",
    "#cur = con.cursor()\n",
    "\n",
    "#for e in bad_index:\n",
    "#    cur.execute(f'''DELETE FROM pisos WHERE id = \"{e}\"''')\n",
    "#con.commit()\n",
    "\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links_por_zonas[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
